replicaCount: 1

image:
  repository: nginx
  tag: stable
  pullPolicy: IfNotPresent

service:
  type: ClusterIP
  port: 80

chaoskube:
  enabled: false
seq:
  enabled: true
  # ingress:
  #   enabled: true
  #   hosts:
  #     - logs.localtest.me 
  #     - seq.localtest.me 
fluentd-elasticsearch:

  image:
    repository: fluentdpython
    tag: v2
  enabled: true
  configMaps:
    system.conf: |-
      <system>
        root_dir /tmp/fluentd-buffers/
      </system>
    fluent.conf: |
      <match fluent.**>
        @type null
      </match>
      <source>
        @type tail
        path /var/log/containers/*.log
        pos_file /var/log/fluentd-containers.log.pos
        time_format %Y-%m-%dT%H:%M:%S.%NZ
        tag kubernetes.*
        format json
        read_from_head true
      </source>

    containers.input.conf: |-
    #   <source>
    #     @id fluentd-containers.log
    #     @type tail
    #     path /var/log/containers/*.log
    #     pos_file /var/log/fluentd-containers.log.pos
    #     time_format %Y-%m-%dT%H:%M:%S.%NZ
    #     tag raw.kubernetes.*
    #     format json
    #     read_from_head true
    #   </source>
    #   # Detect exceptions in the log output and forward them as one log entry.
    #   <match raw.kubernetes.**>
    #     @id raw.kubernetes
    #     @type detect_exceptions
    #     remove_tag_prefix raw
    #     message log
    #     stream stream
    #     multiline_flush_interval 5
    #     max_bytes 500000
    #     max_lines 1000
    #   </match>
    system.input.conf: |-
    #   # Example:
    #   # 2015-12-21 23:17:22,066 [salt.state       ][INFO    ] Completed state [net.ipv4.ip_forward] at time 23:17:22.066081
    #   <source>
    #     @id minion
    #     @type tail
    #     format /^(?<time>[^ ]* [^ ,]*)[^\[]*\[[^\]]*\]\[(?<severity>[^ \]]*) *\] (?<message>.*)$/
    #     time_format %Y-%m-%d %H:%M:%S
    #     path /var/log/salt/minion
    #     pos_file /var/log/salt.pos
    #     tag salt
    #   </source>
    #   # Example:
    #   # Dec 21 23:17:22 gke-foo-1-1-4b5cbd14-node-4eoj startupscript: Finished running startup script /var/run/google.startup.script
    #   <source>
    #     @id startupscript.log
    #     @type tail
    #     format syslog
    #     path /var/log/startupscript.log
    #     pos_file /var/log/startupscript.log.pos
    #     tag startupscript
    #   </source>
    #   # Examples:
    #   # time="2016-02-04T06:51:03.053580605Z" level=info msg="GET /containers/json"
    #   # time="2016-02-04T07:53:57.505612354Z" level=error msg="HTTP Error" err="No such image: -f" statusCode=404
    #   <source>
    #     @id docker.log
    #     @type tail
    #     format /^time="(?<time>[^)]*)" level=(?<severity>[^ ]*) msg="(?<message>[^"]*)"( err="(?<error>[^"]*)")?( statusCode=($<status_code>\d+))?/
    #     path /var/log/docker.log
    #     pos_file /var/log/docker.log.pos
    #     tag docker
    #   </source>
    #   # Example:
    #   # 2016/02/04 06:52:38 filePurge: successfully removed file /var/etcd/data/member/wal/00000000000006d0-00000000010a23d1.wal
    #   <source>
    #     @id etcd.log
    #     @type tail
    #     # Not parsing this, because it doesn't have anything particularly useful to
    #     # parse out of it (like severities).
    #     format none
    #     path /var/log/etcd.log
    #     pos_file /var/log/etcd.log.pos
    #     tag etcd
    #   </source>
    #   # Multi-line parsing is required for all the kube logs because very large log
    #   # statements, such as those that include entire object bodies, get split into
    #   # multiple lines by glog.
    #   # Example:
    #   # I0204 07:32:30.020537    3368 server.go:1048] POST /stats/container/: (13.972191ms) 200 [[Go-http-client/1.1] 10.244.1.3:40537]
    #   <source>
    #     @id kubelet.log
    #     @type tail
    #     format multiline
    #     multiline_flush_interval 5s
    #     format_firstline /^\w\d{4}/
    #     format1 /^(?<severity>\w)(?<time>\d{4} [^\s]*)\s+(?<pid>\d+)\s+(?<source>[^ \]]+)\] (?<message>.*)/
    #     time_format %m%d %H:%M:%S.%N
    #     path /var/log/kubelet.log
    #     pos_file /var/log/kubelet.log.pos
    #     tag kubelet
    #   </source>
    #   # Example:
    #   # I1118 21:26:53.975789       6 proxier.go:1096] Port "nodePort for kube-system/default-http-backend:http" (:31429/tcp) was open before and is still needed
    #   <source>
    #     @id kube-proxy.log
    #     @type tail
    #     format multiline
    #     multiline_flush_interval 5s
    #     format_firstline /^\w\d{4}/
    #     format1 /^(?<severity>\w)(?<time>\d{4} [^\s]*)\s+(?<pid>\d+)\s+(?<source>[^ \]]+)\] (?<message>.*)/
    #     time_format %m%d %H:%M:%S.%N
    #     path /var/log/kube-proxy.log
    #     pos_file /var/log/kube-proxy.log.pos
    #     tag kube-proxy
    #   </source>
    #   # Example:
    #   # I0204 07:00:19.604280       5 handlers.go:131] GET /api/v1/nodes: (1.624207ms) 200 [[kube-controller-manager/v1.1.3 (linux/amd64) kubernetes/6a81b50] 127.0.0.1:38266]
    #   <source>
    #     @id kube-apiserver.log
    #     @type tail
    #     format multiline
    #     multiline_flush_interval 5s
    #     format_firstline /^\w\d{4}/
    #     format1 /^(?<severity>\w)(?<time>\d{4} [^\s]*)\s+(?<pid>\d+)\s+(?<source>[^ \]]+)\] (?<message>.*)/
    #     time_format %m%d %H:%M:%S.%N
    #     path /var/log/kube-apiserver.log
    #     pos_file /var/log/kube-apiserver.log.pos
    #     tag kube-apiserver
    #   </source>
    #   # Example:
    #   # I0204 06:55:31.872680       5 servicecontroller.go:277] LB already exists and doesn't need update for service kube-system/kube-ui
    #   <source>
    #     @id kube-controller-manager.log
    #     @type tail
    #     format multiline
    #     multiline_flush_interval 5s
    #     format_firstline /^\w\d{4}/
    #     format1 /^(?<severity>\w)(?<time>\d{4} [^\s]*)\s+(?<pid>\d+)\s+(?<source>[^ \]]+)\] (?<message>.*)/
    #     time_format %m%d %H:%M:%S.%N
    #     path /var/log/kube-controller-manager.log
    #     pos_file /var/log/kube-controller-manager.log.pos
    #     tag kube-controller-manager
    #   </source>
    #   # Example:
    #   # W0204 06:49:18.239674       7 reflector.go:245] pkg/scheduler/factory/factory.go:193: watch of *api.Service ended with: 401: The event in requested index is outdated and cleared (the requested history has been cleared [2578313/2577886]) [2579312]
    #   <source>
    #     @id kube-scheduler.log
    #     @type tail
    #     format multiline
    #     multiline_flush_interval 5s
    #     format_firstline /^\w\d{4}/
    #     format1 /^(?<severity>\w)(?<time>\d{4} [^\s]*)\s+(?<pid>\d+)\s+(?<source>[^ \]]+)\] (?<message>.*)/
    #     time_format %m%d %H:%M:%S.%N
    #     path /var/log/kube-scheduler.log
    #     pos_file /var/log/kube-scheduler.log.pos
    #     tag kube-scheduler
    #   </source>
    #   # Example:
    #   # I1104 10:36:20.242766       5 rescheduler.go:73] Running Rescheduler
    #   <source>
    #     @id rescheduler.log
    #     @type tail
    #     format multiline
    #     multiline_flush_interval 5s
    #     format_firstline /^\w\d{4}/
    #     format1 /^(?<severity>\w)(?<time>\d{4} [^\s]*)\s+(?<pid>\d+)\s+(?<source>[^ \]]+)\] (?<message>.*)/
    #     time_format %m%d %H:%M:%S.%N
    #     path /var/log/rescheduler.log
    #     pos_file /var/log/rescheduler.log.pos
    #     tag rescheduler
    #   </source>
    #   # Example:
    #   # I0603 15:31:05.793605       6 cluster_manager.go:230] Reading config from path /etc/gce.conf
    #   <source>
    #     @id glbc.log
    #     @type tail
    #     format multiline
    #     multiline_flush_interval 5s
    #     format_firstline /^\w\d{4}/
    #     format1 /^(?<severity>\w)(?<time>\d{4} [^\s]*)\s+(?<pid>\d+)\s+(?<source>[^ \]]+)\] (?<message>.*)/
    #     time_format %m%d %H:%M:%S.%N
    #     path /var/log/glbc.log
    #     pos_file /var/log/glbc.log.pos
    #     tag glbc
    #   </source>
    #   # Example:
    #   # I0603 15:31:05.793605       6 cluster_manager.go:230] Reading config from path /etc/gce.conf
    #   <source>
    #     @id cluster-autoscaler.log
    #     @type tail
    #     format multiline
    #     multiline_flush_interval 5s
    #     format_firstline /^\w\d{4}/
    #     format1 /^(?<severity>\w)(?<time>\d{4} [^\s]*)\s+(?<pid>\d+)\s+(?<source>[^ \]]+)\] (?<message>.*)/
    #     time_format %m%d %H:%M:%S.%N
    #     path /var/log/cluster-autoscaler.log
    #     pos_file /var/log/cluster-autoscaler.log.pos
    #     tag cluster-autoscaler
    #   </source>
    #   # Logs from systemd-journal for interesting services.
    #   <source>
    #     @id journald-docker
    #     @type systemd
    #     matches [{ "_SYSTEMD_UNIT": "docker.service" }]
    #     <storage>
    #       @type local
    #       persistent true
    #       path /var/log/journald-docker.pos
    #     </storage>
    #     read_from_head true
    #     tag docker
    #   </source>
    #   <source>
    #     @id journald-kubelet
    #     @type systemd
    #     matches [{ "_SYSTEMD_UNIT": "kubelet.service" }]
    #     <storage>
    #       @type local
    #       persistent true
    #       path /var/log/journald-kubelet.pos
    #     </storage>
    #     read_from_head true
    #     tag kubelet
    #   </source>
    #   <source>
    #     @id journald-node-problem-detector
    #     @type systemd
    #     matches [{ "_SYSTEMD_UNIT": "node-problem-detector.service" }]
    #     <storage>
    #       @type local
    #       persistent true
    #       path /var/log/journald-node-problem-detector.pos
    #     </storage>
    #     read_from_head true
    #     tag node-problem-detector
    #   </source>
    forward.input.conf: |-
    #   # Takes the messages sent over TCP
    #   <source>
    #     @type forward
    #   </source>
    monitoring.conf: |-
    #   # Prometheus Exporter Plugin
    #   # input plugin that exports metrics
    #   <source>
    #     @type prometheus
    #   </source>
    #   <source>
    #     @type monitor_agent
    #   </source>
    #   # input plugin that collects metrics from MonitorAgent
    #   <source>
    #     @type prometheus_monitor
    #     <labels>
    #       host ${hostname}
    #     </labels>
    #   </source>
    #   # input plugin that collects metrics for output plugin
    #   <source>
    #     @type prometheus_output_monitor
    #     <labels>
    #       host ${hostname}
    #     </labels>
    #   </source>
    #   # input plugin that collects metrics for in_tail plugin
    #   <source>
    #     @type prometheus_tail_monitor
    #     <labels>
    #       host ${hostname}
    #     </labels>
    #   </source>
    output.conf: |
      # Enriches records with Kubernetes metadata
      <match kubernetes.var.log.containers.**fluentd**.log>
        @type null
      </match>
      <match kubernetes.var.log.containers.**kube-system**.log>
        @type null
      </match>
      <match kubernetes.var.log.containers.opsdemo-**.log>
        @type null
      </match>
      <filter kubernetes.**>
        @type kubernetes_metadata
      </filter>
      # <match **>
      #   @type stdout
      # </match>
      <match **>
        @type exec
        command python -c 'import requests; requests.post("http://opsdemo-seq/api/events/raw?clef", data={"Events": [{"Timestamp": "2015-05-09T22:09:08.12345+10:00", "Level": "Warning", "MessageTemplate": "Disk space is low on {Drive}", "Properties": { "Drive": "C:", "MachineName": "nblumhardt-rmbp" } }]})'
        <buffer>
          @type file
          path /path/to/buffer_path
          flush_interval 5s # for debugging/checking
        </buffer>
        <format>
          @type tsv
          keys log
        </format>
      </match>
prometheus:
  enabled: true
  server:
    ingress:
      enabled: true
      hosts:
        - prometheus.localtest.me 
  alertmanager:
    ingress:
      enabled: true
      hosts:
        - prometheus-alertmanager.localtest.me

prometheusnodeexporter:
  enabled: true
  serviceAccount:
    name: node-exporter

kubernetes-dashboard:
  enabled: false
  ingress:
    enabled: true
    hosts:
    - dashboard.localtest.me

grafana:
  image:
    repository: shyamtech/azuregrafana
    tag: latest
    pullPolicy: IfNotPresent
  enabled: true
  ingress:
    enabled: true
    hosts:
      - grafana.localtest.me
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
      - name: Prometheus
        type: prometheus
        url: "http://opsdemo-prometheus-server"
        access: proxy
        isDefault: true

  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
      - name: 'default'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        editable: true
        options:
          path: /var/lib/grafana/dashboards/default

  dashboards:
    default:
      kubernetes-monitoring:
        gnetId: 315
        revision: 3
        datasource: Prometheus
      kubernetes-all-nodes:
        gnetId: 3131
        revision: 1
        datasource: Prometheus
      kubernetes-cluster-monitoring:
        gnetId: 3119
        revision: 2
        datasource: Prometheus
      kubernetes-cluster:
        gnetId: 7249
        revision: 1
        datasource: Prometheus
      kubernetes-dashboard:
        url: https://raw.githubusercontent.com/Azure/blackbelt-aks-hackfest/master/labs/helper-files/grafana-dashboard.json
        datasource: Prometheus
      ingress-dashboard:
        url: https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/grafana/dashboards/nginx.yaml
        datasource: Prometheus
  ingress:
    enabled: true
    hosts:
      - grafana.localtest.me

nginx-ingress:
  enabled: false
  controller:
    stats:
      enabled: true
    metrics:
      enabled: true
      service:
        annotations:
          prometheus.io/port: "10254"
          prometheus.io/scrape: "true"
ingress:
  enabled: true
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  path: /
  hosts:
    - site.localtest.me
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

